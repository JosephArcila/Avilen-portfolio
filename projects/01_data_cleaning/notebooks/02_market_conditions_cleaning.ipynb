{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Market Conditions Data Processing (市況データ処理)\n",
        "\n",
        "## Overview\n",
        "This notebook processes market conditions data from multiple countries, handling various date formats and currency notations. It converts daily/weekly price data into a standardized monthly format.\n",
        "\n",
        "### Input Data\n",
        "- Source: Excel file with multiple sheets\n",
        "- Countries: Brazil, Thailand, USA, China\n",
        "- Date Range: Varies by country\n",
        "- Currencies: Different units by country\n",
        "\n",
        "### Output Format\n",
        "- Monthly averaged data\n",
        "- Standardized currency columns\n",
        "- Clean, consistent index in yyyymm format"
      ],
      "metadata": {
        "id": "a9TUztvaIh4-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup and Data Loading"
      ],
      "metadata": {
        "id": "wNXqCPuMImlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file paths and sheet names\n",
        "FILE_PATH = \"/content/drive/Shareddrives/125-2日本ハム-業務委託共有/前処理作業ファイル for Joseph-san/Before Preprocessing/2024-06断面データ/★O PREÇO （24.5.29）.xlsx\"\n",
        "BRASIL_SHEET = \"ブラジル週間価格（2013年5月-）\"\n",
        "THAI_SHEET = \"タイ週間価格（2014年1月-）\"\n",
        "USA_SHEET = \"アメリカ週間価格（2014年12月-）\"\n",
        "CHINA_SHEET = \"中国鴨週間価格（2023年5月-）\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leD4s-bkIieg",
        "outputId": "c2de4129-067d-4186-f753-505d462902ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Define Helper Functions"
      ],
      "metadata": {
        "id": "vhq3_aw6Iu7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Helper Functions\n",
        "def get_first_and_last_year(sheet_name):\n",
        "    \"\"\"Extract first and last years from a sheet.\"\"\"\n",
        "    data = pd.read_excel(FILE_PATH, sheet_name=sheet_name, header=None)\n",
        "    # Fix deprecation warning by using pd.Series.str.contains directly\n",
        "    year_mask = data.iloc[:, 0].str.contains(r'\\d{4}年', na=False)\n",
        "\n",
        "    first_year_position = year_mask.iloc[::1].idxmax()\n",
        "    first_year = int(data.iloc[first_year_position, 0][:4])\n",
        "\n",
        "    last_year_position = year_mask.iloc[::-1].idxmax()\n",
        "    last_year = int(data.iloc[last_year_position, 0][:4])\n",
        "\n",
        "    return first_year, last_year\n",
        "\n",
        "def get_table_position(sheet_name, year):\n",
        "    \"\"\"Get start and end positions for a year's data.\"\"\"\n",
        "    data = pd.read_excel(FILE_PATH, sheet_name=sheet_name, header=None)\n",
        "\n",
        "    start_index = data.index[data.iloc[:, 0] == f\"{year}年\"].tolist()[0] + 1\n",
        "    try:\n",
        "        end_index = data.index[data.iloc[:, 0] == f\"{year+1}年\"].tolist()[0] - 1\n",
        "    except IndexError:\n",
        "        end_index = data.index.stop\n",
        "\n",
        "    return {year: (start_index, end_index)}\n",
        "\n",
        "def split_table_by_year(table_data, year, country):\n",
        "    \"\"\"Split table data if it contains multiple years.\"\"\"\n",
        "    # Fix deprecation warning by using pd.Series.str.contains directly\n",
        "    contains_year = table_data.iloc[0].str.contains(r'\\d{4}年', na=False)[1:]\n",
        "    year_positions = contains_year[contains_year].index.tolist()\n",
        "\n",
        "    if len(year_positions) > 1:\n",
        "        print(f\"Splitting {country}_{year} table into more tables\")\n",
        "        tables = {}\n",
        "        for i in range(len(year_positions) - 1):\n",
        "            start_col, end_col = year_positions[i], year_positions[i+1] - 1\n",
        "            sub_table = table_data.iloc[1:, start_col:end_col+1]\n",
        "            sub_table = pd.concat([table_data.iloc[1:, 0], sub_table], axis=1)\n",
        "            tables[year-(i+1)] = sub_table\n",
        "\n",
        "        last_sub_table = table_data.iloc[1:, year_positions[-1]:]\n",
        "        last_sub_table = pd.concat([table_data.iloc[1:, 0], last_sub_table], axis=1)\n",
        "        tables[year] = last_sub_table\n",
        "        return tables\n",
        "    else:\n",
        "        return {year: table_data.iloc[1:]}\n",
        "\n",
        "def set_first_column_as_index(tables):\n",
        "    \"\"\"Set the first column as index for all tables.\"\"\"\n",
        "    for year in tables:\n",
        "        tables[year].set_index(tables[year].columns[0], inplace=True)\n",
        "    return tables\n",
        "\n",
        "def set_first_row_as_column_names(tables):\n",
        "    \"\"\"Use the first row as column names for all tables.\"\"\"\n",
        "    for year in tables:\n",
        "        tables[year].columns = tables[year].iloc[0]\n",
        "        tables[year] = tables[year].drop(tables[year].index[0])\n",
        "    return tables\n",
        "\n",
        "def transpose_tables(tables):\n",
        "    \"\"\"Transpose all tables.\"\"\"\n",
        "    return {year: table.transpose() for year, table in tables.items()}\n",
        "\n",
        "def add_country_prefix_to_columns(tables):\n",
        "    \"\"\"Add country prefix to all column names.\"\"\"\n",
        "    for year in tables:\n",
        "        tables[year].columns = [f\"{country}_{col}\" for col in tables[year].columns]\n",
        "    return tables\n",
        "\n",
        "def concatenate_country_dataframes(country_dict):\n",
        "    \"\"\"Concatenate tables for each country.\"\"\"\n",
        "    result = {}\n",
        "    for country, tables in country_dict.items():\n",
        "        result[country + \"_df\"] = pd.concat(tables.values())\n",
        "    return result"
      ],
      "metadata": {
        "id": "iUsxsp6CIpet"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Processing Functions"
      ],
      "metadata": {
        "id": "u7EFURlYI4g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_year_tables(sheet_name):\n",
        "    \"\"\"Process all years for a given sheet.\"\"\"\n",
        "    first_year, last_year = get_first_and_last_year(sheet_name)\n",
        "    all_tables = {}\n",
        "\n",
        "    for year in range(first_year, last_year + 1):\n",
        "        start_index, end_index = get_table_position(sheet_name, year)[year]\n",
        "        table_data = pd.read_excel(\n",
        "            FILE_PATH,\n",
        "            sheet_name=sheet_name,\n",
        "            header=None,\n",
        "            skiprows=start_index-1,\n",
        "            nrows=end_index-start_index+1\n",
        "        )\n",
        "        split_tables = split_table_by_year(table_data, year, sheet_name.split('（')[0])\n",
        "        all_tables.update(split_tables)\n",
        "\n",
        "    return all_tables\n",
        "\n",
        "def process_dataframe(tables):\n",
        "    \"\"\"Clean and standardize dataframe format.\"\"\"\n",
        "    processed_tables = {}\n",
        "\n",
        "    for year, df in tables.items():\n",
        "        # Convert dates to YYYYMMDD format\n",
        "        def convert_to_date(value):\n",
        "            if isinstance(value, str) and value.endswith('月'):\n",
        "                month_num = int(value[:-1])\n",
        "                return f\"{year}{month_num:02d}01\"\n",
        "            elif isinstance(value, (pd.Timestamp, datetime)):\n",
        "                if value.year != year:\n",
        "                    value = value.replace(year=year)\n",
        "                return value.strftime('%Y%m%d')\n",
        "            return value\n",
        "\n",
        "        # Process dates and clean data\n",
        "        df.index = df.index.map(convert_to_date)\n",
        "        mask = df.index.astype(str).str.contains('平均') | df.index.isna()\n",
        "        df = df[~mask]\n",
        "        df.index.name = None\n",
        "\n",
        "        processed_tables[year] = df\n",
        "\n",
        "    return processed_tables"
      ],
      "metadata": {
        "id": "2v_mZ03OIzMz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Process Country Data"
      ],
      "metadata": {
        "id": "T22OUR5EJB3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary mapping sheet names to country codes\n",
        "sheet_dict = {\n",
        "    BRASIL_SHEET: \"ブラジル\",\n",
        "    THAI_SHEET: \"タイ\",\n",
        "    USA_SHEET: \"アメリカ\",\n",
        "    CHINA_SHEET: \"中国\"\n",
        "}\n",
        "\n",
        "# Process all sheets\n",
        "country_dict = {}\n",
        "for sheet_name, country in sheet_dict.items():\n",
        "    # Process each country's data\n",
        "    tables = get_all_year_tables(sheet_name)\n",
        "    tables = set_first_column_as_index(tables)\n",
        "    tables = set_first_row_as_column_names(tables)\n",
        "    tables = transpose_tables(tables)\n",
        "    tables = process_dataframe(tables)\n",
        "\n",
        "    # Add country prefix and store results\n",
        "    globals()[country] = tables\n",
        "    add_country_prefix_to_columns(tables)\n",
        "    country_dict[country] = tables\n",
        "\n",
        "# Concatenate dataframes for each country\n",
        "concatenated_dataframes = concatenate_country_dataframes(country_dict)\n",
        "\n",
        "# Assign concatenated dataframes to variables\n",
        "for variable_name, dataframe in concatenated_dataframes.items():\n",
        "    globals()[variable_name] = dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hocqoIf5I8p4",
        "outputId": "db083181-ffbe-49fd-cb04-8c438f53454d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting アメリカ週間価格_2014 table into more tables\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Clean and Standardize Data"
      ],
      "metadata": {
        "id": "_jztyeZGJzdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set pandas option to handle downcasting behavior\n",
        "pd.set_option('future.no_silent_downcasting', True)\n",
        "\n",
        "# Clean Thai data (remove problematic rows)\n",
        "タイ_df = タイ_df[タイ_df.index != '-']\n",
        "\n",
        "# Combine all country data\n",
        "市況 = pd.concat([ブラジル_df, タイ_df, アメリカ_df, 中国_df], axis=1)\n",
        "\n",
        "# Clean numeric data\n",
        "for column in 市況.columns:\n",
        "    try:\n",
        "        # Convert to string and clean separators\n",
        "        市況[column] = 市況[column].astype(str).str.replace('..', '.')\n",
        "\n",
        "        # Create a mask for values to replace with NaN\n",
        "        nan_mask = (市況[column] == 'nan') | \\\n",
        "                  (市況[column] == 'NaT') | \\\n",
        "                  (市況[column] == 'ＮＡ') | \\\n",
        "                  (市況[column] == '-')\n",
        "\n",
        "        # Replace values using mask\n",
        "        市況.loc[nan_mask, column] = np.nan\n",
        "\n",
        "        # Convert to numeric\n",
        "        市況[column] = pd.to_numeric(市況[column], errors='coerce')\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in column '{column}': {str(e)}\")\n",
        "        raise e\n",
        "\n",
        "# Sort by date\n",
        "市況 = 市況.sort_index()"
      ],
      "metadata": {
        "id": "OzUHBykpJE15"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Handle Special Cases: Brazil Currency Columns"
      ],
      "metadata": {
        "id": "Q0VThZMLJ8IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to monthly data with updated resample parameter\n",
        "市況.index = pd.to_datetime(市況.index, format='%Y%m%d')\n",
        "monthly_data = 市況.resample('ME').mean()\n",
        "monthly_data.index = monthly_data.index.strftime('%Y%m')\n",
        "\n",
        "# Unify BRR/BRL columns\n",
        "def unify_columns(df, brr_col, brl_col, new_col_name):\n",
        "    df[new_col_name] = df[brr_col].fillna(df[brl_col])\n",
        "    return df.drop([brr_col, brl_col], axis=1)\n",
        "\n",
        "# List of columns to unify\n",
        "column_pairs = [\n",
        "    ('ブラジル_生鶏価格(SP、BRR/KG )', 'ブラジル_生鶏価格(SP、BRL/KG )', 'ブラジル_生鶏価格_統合'),\n",
        "    ('ブラジル_卸売価格(SP、BRR/KG )　月毎　翌月更新', 'ブラジル_卸売価格(SP、BRL/KG )　月毎　翌月更新', 'ブラジル_卸売価格_統合'),\n",
        "    ('ブラジル_小売り価格(SP、BRR/KG )　月毎　翌月更新', 'ブラジル_小売り価格(SP、BRL/KG )　月毎　翌月更新', 'ブラジル_小売り価格_統合'),\n",
        "    ('ブラジル_卵(SP BRR/ダース)', 'ブラジル_卵(SP BRL/ダース)', 'ブラジル_卵_統合'),\n",
        "    ('ブラジル_為替　USD=BRR', 'ブラジル_為替　USD=BRL', 'ブラジル_為替_統合')\n",
        "]\n",
        "\n",
        "# Process each pair\n",
        "monthly_data_cleaned = monthly_data.copy()\n",
        "for brr_col, brl_col, new_col_name in column_pairs:\n",
        "    monthly_data_cleaned = unify_columns(monthly_data_cleaned, brr_col, brl_col, new_col_name)"
      ],
      "metadata": {
        "id": "e_KE41YnJ3Xj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Export Results"
      ],
      "metadata": {
        "id": "7YHkxQieMPP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CSV filename\n",
        "csv_filename = '市況_mm.csv'\n",
        "\n",
        "# Convert the DataFrame to a CSV file\n",
        "monthly_data_cleaned.to_csv(csv_filename, index=True)\n",
        "\n",
        "# Download the result\n",
        "from google.colab import files\n",
        "files.download(csv_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uWB8rCXLJ-06",
        "outputId": "8ec842bc-b1c8-49b6-97a7-66263c1406a8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6fc92803-79df-4b90-9309-aa8f023a81a3\", \"\\u5e02\\u6cc1_mm.csv\", 22870)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}